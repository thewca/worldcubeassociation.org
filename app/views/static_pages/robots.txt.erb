# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
<% unless EnvConfig.WCA_LIVE_SITE? %>
User-agent: *
Disallow: /
<% end %>
<%# See https://docs.google.com/document/d/1XND2oUwGZbwXLXaDMDY4moQwnsEpET7zSaqTukrULUM %>
User-agent: *
Disallow: /search
Disallow: /api/v0/search
<%# See https://docs.google.com/document/d/1epN2l3HcgbQHME4U2GT7zDGjAeulqiEbcslFeyfGX4I %>
<%# Note that we're only blocking URLs that have query params (with a ? towards the end) %>
<%# so that the "basic" rankings for each event and the "general" records page still appear on Google %>
<%# But the bots don't bother us with recomputing every permutation of country x event. %>
Disallow: /results/rankings/*?*
Disallow: /results/records?*
Disallow: /*.php*
